{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f54f424-046b-4fd0-a65c-aff1f16fbbf7",
   "metadata": {},
   "source": [
    "# 0. Librerías y funciones almacenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88def746-d7ce-40de-94de-6d1b237fab81",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Librerías\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m webdriver\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mby\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m By\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfirefox\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Options\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "# Librerías\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "import camelot\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdd1d88-c535-4422-b0a9-8cc10cffa15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar preferencias\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import ctypes\n",
    "from ctypes.util import find_library\n",
    "find_library(\"\".join((\"gsdll\", str(ctypes.sizeof(ctypes.c_voidp) * 8), \".dll\")))\n",
    "\n",
    "options = Options()\n",
    "options.headless = True\n",
    "\n",
    "options.set_preference('permissions.default.image', 2)\n",
    "options.set_preference('dom.ipc.plugins.enabled.libflashplayer.so', False)\n",
    "options.set_preference(\"browser.download.folderList\", 2)\n",
    "options.set_preference(\"browser.download.manager.showWhenStarting\", False)\n",
    "options.set_preference('pdfjs.disabled', True)\n",
    "options.set_preference(\"browser.download.dir\", \"C:\\\\Users\\\\HP SUPPORT\\\\Documents\\\\trabajos\\\\DataMining\\\\pdfs2023\")\n",
    "options.set_preference(\"browser.helperApps.neverAsk.saveToDisk\", \"application/pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303c14d4-6eef-41aa-9c2f-7e9ad0bb378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones\n",
    "def contiene_substring(dataframe, substrings,extract=False):\n",
    "    for columna in dataframe.columns:\n",
    "        for indice, valor in dataframe[columna].items():\n",
    "            for substring in substrings:\n",
    "                if substring in str(valor):\n",
    "                    return substring if extract==True else True \n",
    "    return False\n",
    "\n",
    "diccionario_meses = {\n",
    "    1: \"Enero\",\n",
    "    2: \"Enero\",\n",
    "    3: \"Enero\",\n",
    "    4: \"Enero\",\n",
    "    5: \"Febrero\",\n",
    "    6: \"Febrero\",\n",
    "    7: \"Febrero\",\n",
    "    8: \"Marzo\",\n",
    "    9: \"Marzo\",\n",
    "    10: \"Marzo\",\n",
    "    11: \"Marzo\",\n",
    "    12: \"Marzo\",\n",
    "    13: \"Abril\",\n",
    "    14: \"Abril\",\n",
    "    15: \"Abril\",\n",
    "    16: \"Abril\",\n",
    "    17: \"Mayo\",\n",
    "    18: \"Mayo\",\n",
    "    19: \"Mayo\",\n",
    "    20: \"Mayo\",\n",
    "    21: \"Mayo\",\n",
    "    22: \"Junio\",\n",
    "    23: \"Junio\",\n",
    "    24: \"Junio\",\n",
    "    25: \"Junio\",\n",
    "    26: \"Julio\",\n",
    "    27: \"Julio\",\n",
    "    28: \"Julio\",\n",
    "    29: \"Julio\",\n",
    "    30: \"Julio\",\n",
    "    31: \"Agosto\",\n",
    "    32: \"Agosto\",\n",
    "    33: \"Agosto\",\n",
    "    34: \"Agosto\",\n",
    "    35: \"Agosto\",\n",
    "    36: \"Setiembre\",\n",
    "    37: \"Setiembre\",\n",
    "    38: \"Setiembre\",\n",
    "    39: \"Setiembre\",\n",
    "    40: \"Octubre\",\n",
    "    41: \"Octubre\",\n",
    "    42: \"Octubre\",\n",
    "    43: \"Octubre\",\n",
    "    44: \"Octubre\",\n",
    "    45: \"Noviembre\",\n",
    "    46: \"Noviembre\",\n",
    "    47: \"Noviembre\",\n",
    "    48: \"Noviembre\",\n",
    "    49: \"Diciembre\",\n",
    "    50: \"Diciembre\",\n",
    "    51: \"Diciembre\",\n",
    "    52: \"Diciembre\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60171c85-05b6-426b-aaf3-75c6d6b2498b",
   "metadata": {},
   "source": [
    "# 1. Preparación de casos de dengue, 2020-2024\n",
    "\n",
    "En las enumeraciones se encuentra nuestro paso a paso para recuperar la información. No obstante, no es necesario que lo cargue todo, debido a que desde 2023 es un proceso que demora horas. Para la obtención de la tabla completa, diríganse a la enumeración 1.* que está al final del punto 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92613023",
   "metadata": {},
   "source": [
    "## 1.1. Recolección de casos de dengue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb03d3f2-a516-4d35-a65c-e5eb18703fe2",
   "metadata": {},
   "source": [
    "### 1.1.1. Casos de incidencias de dengue en la actualidad, 2024\n",
    "\n",
    "* FUENTE: https://www.dge.gob.pe/sala-situacional-dengue/#grafico01\n",
    "* AUTOR: Centro Nacional de Epidemiología, Prevención y Control de Enfermedades (CDC) del Ministerio de Salud (MINSA) del Perú\n",
    "* ÚLTIMA ACTUALIZACIÓN: 14 de abril, 2024\n",
    "* ARCHIVOS DESCARGADOS: 'Sala situacional de enfermedades metaxénicas', derivado de la sección 'Según semana epidemiológica'. Departamentos: 'Lima' y 'Callao'.\n",
    "\n",
    "Esta página creada por el CDC MINSA informa sobre las incidencias de dengue en función de la semana epidemiológica del 2024.\n",
    "Por el enfoque de nuestro estudio, descargamos la información de los departamentos de Lima y El Callao, y pretendemos unificar sus registros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a790a27-a7b3-4445-bc28-2b32a8b436e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de incidencias: (1552, 5) \n",
      "Lista de atributos: ['Año', 'Provincia', 'Distrito', 'Semana', 'Casos'] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Año</th>\n",
       "      <th>Semana</th>\n",
       "      <th>Casos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1552.0</td>\n",
       "      <td>1552.000000</td>\n",
       "      <td>1552.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>32.892397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.611258</td>\n",
       "      <td>88.026896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>12.250000</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>906.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Año       Semana        Casos\n",
       "count  1552.0  1552.000000  1552.000000\n",
       "mean   2024.0     8.500000    32.892397\n",
       "std       0.0     4.611258    88.026896\n",
       "min    2024.0     1.000000     0.000000\n",
       "25%    2024.0     4.750000     0.000000\n",
       "50%    2024.0     8.500000     2.000000\n",
       "75%    2024.0    12.250000    22.000000\n",
       "max    2024.0    16.000000   906.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importación y agrupación de los registros\n",
    "lima = pd.read_excel(\"anexos/incidencias_dengue/lima2024.xlsx\",sheet_name=\"Sheet1\")\n",
    "callao = pd.read_excel(\"anexos/incidencias_dengue/callao2024.xlsx\",sheet_name=\"Sheet1\")\n",
    "base2024 = pd.concat([lima,callao],axis=0)\n",
    "\n",
    "# Agregación de columna suma\n",
    "base2024['Casos'] = base2024['Sin signos de alarma_total'] + base2024['Con signos de alarma_total'] + base2024['Grave_total']\n",
    "base2024['Año'] = 2024\n",
    "base2024 = base2024[['Año','Provincia','Distrito','Semana','Casos']] \n",
    "\n",
    "# Información\n",
    "print(f'Dimensiones de incidencias: {base2024.shape} \\nLista de atributos: {list(base2024.columns)} ') # (1131 filas, 7 columnas)\n",
    "base2024.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a421f3a-0cdb-45c1-9e24-e5c4b424abda",
   "metadata": {},
   "source": [
    "Se pueden realizar observaciones preliminares sobre el dataset:\n",
    "* Contiene la totalidad de sus datos (tiene 1131 registros y cada columna cuenta de 1131 valores).\n",
    "* No se deberían sumar las semanas, debido a que solo pauta de agrupación de tiempo. Los estadísticos de esa columna no dicen nada.\n",
    "* Los valores de los cuartiles hasta el 75% informan que la mayor parte del dataset cuenta con valores bastante pequeño, lo que también lo confirman las desviaciones estándar grandes y positivas. La dispersión de los datos de cada variable, tal cual está el dataset, es asimétrica positiva."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb6be1a-3fa0-4907-a5f7-930a8386c1b0",
   "metadata": {},
   "source": [
    "### 1.1.2. Casos de incidencias de dengue 2020-2022\n",
    "\n",
    "* FUENTE: https://www.datosabiertos.gob.pe/dataset/vigilancia-epidemiol%C3%B3gica-de-dengue\n",
    "* AUTOR: Centro Nacional de Epidemiología, Prevención y Control de Enfermedades (CDC) del Ministerio de Salud (MINSA) del Perú\n",
    "* ÚLTIMA ACTUALIZACIÓN: 22 de noviembre, 2023\n",
    "* ARCHIVOS DESCARGADOS: 'datos_abiertos_vigilancia_dengue.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf14e126-7e73-483c-aeec-8866b59c5f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 87871: expected 14 fields, saw 16\n",
      "Skipping line 88799: expected 14 fields, saw 16\n",
      "Skipping line 89573: expected 14 fields, saw 16\n",
      "\n",
      "Skipping line 176478: expected 14 fields, saw 16\n",
      "Skipping line 177184: expected 14 fields, saw 16\n",
      "Skipping line 177191: expected 14 fields, saw 16\n",
      "Skipping line 183099: expected 14 fields, saw 16\n",
      "\n",
      "Skipping line 293518: expected 14 fields, saw 16\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Año</th>\n",
       "      <th>Provincia</th>\n",
       "      <th>Distrito</th>\n",
       "      <th>Semana</th>\n",
       "      <th>Casos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>CALLAO</td>\n",
       "      <td>VENTANILLA</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>CALLAO</td>\n",
       "      <td>VENTANILLA</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>CALLAO</td>\n",
       "      <td>VENTANILLA</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>LIMA</td>\n",
       "      <td>ATE</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>LIMA</td>\n",
       "      <td>ATE</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>2022</td>\n",
       "      <td>LIMA</td>\n",
       "      <td>VILLA MARIA DEL TRIUNFO</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>2022</td>\n",
       "      <td>LIMA</td>\n",
       "      <td>VILLA MARIA DEL TRIUNFO</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>2022</td>\n",
       "      <td>LIMA</td>\n",
       "      <td>VILLA MARIA DEL TRIUNFO</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>2022</td>\n",
       "      <td>LIMA</td>\n",
       "      <td>VILLA MARIA DEL TRIUNFO</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>2022</td>\n",
       "      <td>LIMA</td>\n",
       "      <td>VILLA MARIA DEL TRIUNFO</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>478 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Año Provincia                 Distrito  Semana  Casos\n",
       "0    2020    CALLAO               VENTANILLA       8      2\n",
       "1    2020    CALLAO               VENTANILLA      10      1\n",
       "2    2020    CALLAO               VENTANILLA      14      1\n",
       "3    2020      LIMA                      ATE      10      1\n",
       "4    2020      LIMA                      ATE      15      1\n",
       "..    ...       ...                      ...     ...    ...\n",
       "473  2022      LIMA  VILLA MARIA DEL TRIUNFO      18      4\n",
       "474  2022      LIMA  VILLA MARIA DEL TRIUNFO      19      4\n",
       "475  2022      LIMA  VILLA MARIA DEL TRIUNFO      20      2\n",
       "476  2022      LIMA  VILLA MARIA DEL TRIUNFO      21      1\n",
       "477  2022      LIMA  VILLA MARIA DEL TRIUNFO      22      1\n",
       "\n",
       "[478 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el dataset de 2000 al 2022\n",
    "peru2000_2022 = pd.read_csv(\"anexos/incidencias_dengue/peru2000_2022.csv\",sep=',',on_bad_lines='warn')\n",
    "to2022 = peru2000_2022.loc[((peru2000_2022['departamento']=='LIMA') | (peru2000_2022['departamento']=='CALLAO')) & ((peru2000_2022['ano'] <= 2022) & (peru2000_2022['ano'] >= 2020))]\n",
    "to2022 = to2022[['ano','provincia','distrito','semana']]\n",
    "to2022['casos'] = 1\n",
    "to2022.set_index(['ano','provincia','distrito','semana'],inplace=True)\n",
    "\n",
    "# Agruparlo al formato de trabajo\n",
    "base2022 = to2022.groupby(level=[0,1,2,3])['casos'].sum().reset_index()\n",
    "base2022.columns = ['Año','Provincia','Distrito','Semana','Casos']\n",
    "base2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3324b9-9d5f-42f9-bb08-dc27b4fc17c0",
   "metadata": {},
   "source": [
    "### 1.1.3. Casos de incidencias de dengue 2023\n",
    "\n",
    "* FUENTE: https://www.dge.gob.pe/portalnuevo/informacion-publica/situacion-del-dengue-en-el-peru/\n",
    "* AUTOR: Centro Nacional de Epidemiología, Prevención y Control de Enfermedades (CDC) del Ministerio de Salud (MINSA) del Perú\n",
    "* ÚLTIMA ACTUALIZACIÓN: 29 de diciembre, 2023\n",
    "* ARCHIVOS DESCARGADOS: Todos los .pdf del año 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894aa813-3596-4517-8dae-0023a9781739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear instancia del navegador\n",
    "driver = webdriver.Firefox(options=options)\n",
    "driver.implicitly_wait(300)\n",
    "\n",
    "# Abrir url en el driver\n",
    "driver.get('https://www.dge.gob.pe/epipublic/publico/listado/13/2023/0')\n",
    "driver.maximize_window()\n",
    "time.sleep(5)\n",
    "\n",
    "# Colocar 50 registros por página\n",
    "selectPaginacion = Select(driver.find_element(By.XPATH, '//select[@name=\"casosIndividual_length\"]'))\n",
    "selectPaginacion.select_by_visible_text('50')\n",
    "time.sleep(2)\n",
    "\n",
    "# Tablas\n",
    "filas = driver.find_elements(By.XPATH, '//a[text()=\"Ver archivo\"]')\n",
    "for fila in filas:\n",
    "    fila.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cacb581-93a3-4269-8682-18a8857a01f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar nombre de los pdfs\n",
    "for pdf in os.listdir('pdfs2023'):\n",
    "    if len(pdf)<=17: pass\n",
    "    else: os.rename(f\"anexos/pdfs2023/{pdf}\",f\"pdfs2023/{pdf.split('_')[0] + '_' + pdf.split('_')[1]}.pdf\")\n",
    "\n",
    "# EXCLUSIVAMENTE QUE CONTENGAN LAS PALABRAS CLAVES 'LIMA', 'Lima', 'Callao' y '2022 - 2023*'\n",
    "pdfscraping = {'semana':[],\n",
    "               'tablas':[]}\n",
    "claves = ['LIMA','Lima','Callao','2022* - 2023*']\n",
    "\n",
    "for i in range(1,53):\n",
    "    if os.path.exists(f'anexos/pdfs2023/dengue_2023{i}.pdf'):\n",
    "        tables = camelot.read_pdf(f'anexos/pdfs2023/dengue_2023{i}.pdf',flavor='stream',pages='all')\n",
    "        tablas_interes = [tabla.df for tabla in tables if any(tabla.df.apply(lambda column: column.astype(str).str.contains('|'.join(claves)).any()))]\n",
    "        \n",
    "        pdfscraping['semana'] += [i]\n",
    "        pdfscraping['tablas'] += [tablas_interes]\n",
    "    else: pass\n",
    "\n",
    "    if i in [5,10,15,20,25,30,35,40,45,50]:\n",
    "        print(f'Checkpoint {i}: {datetime.now()}')\n",
    "\n",
    "# Guardarlo para reusarlo en otra sesión\n",
    "with open(\"anexos/pdfs2023/pdfscraping.obj\",'wb') as filehandler:\n",
    "    pickle.dump(pdfscraping,filehandler)\n",
    "\n",
    "# Revisar cuantas tablas se tienen\n",
    "acumulados = {'n_tablas':[]}\n",
    "for i in range(len(pdfscraping['semana'])):\n",
    "    acumulados['n_tablas'] += [len(pdfscraping['tablas'][i])]\n",
    "\n",
    "control = pd.DataFrame(acumulados,index=pdfscraping['semana'])\n",
    "control.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8112ce-9fce-44c3-8a6e-598c4d0db137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seteo de las variables y los diccionarios\n",
    "agrups = ['Lima Region','Callao','Lima Metropolitana','DIRIS Lima Norte','DIRIS Lima Este','DIRIS Lima Sur','DIRIS Lima Centro']\n",
    "print('Inicio procesamiento: ', datetime.now())\n",
    "\n",
    "hemeroteca = []\n",
    "# Bucle de limpieza de tablas por cada año\n",
    "for i in range(len(pdfscraping['tablas'])):\n",
    "    tablas = pdfscraping['tablas'][i]\n",
    "    sem = f\"SE {str(pdfscraping['semana'][i]).zfill(2)}\"\n",
    "    for tabla in tablas:\n",
    "        # Buscar inicio y final de la tabla\n",
    "        indexacion = 0\n",
    "        for col in range(tabla.shape[1]):\n",
    "            for indice, valor in tabla.iloc[:,col].items():\n",
    "                if valor.isupper():\n",
    "                    indexacion = indice\n",
    "                    break\n",
    "\n",
    "        # Índice de columna desde SE\n",
    "        poscol = 0\n",
    "        for row in range(tabla.shape[0]):\n",
    "            for column in range(len(tabla.columns)):\n",
    "                if sem in tabla.iloc[row,column]:\n",
    "                    poscol = column\n",
    "                    break\n",
    "\n",
    "        # Agrupar tabla en las direcciones distritales        \n",
    "        agrupar = contiene_substring(tabla,agrups,True)\n",
    "        \n",
    "        # Transformar tabla        \n",
    "        transtable = pd.concat([tabla.iloc[:,0],tabla.iloc[:, poscol]],axis=1,ignore_index=True)\n",
    "        transtable = transtable.iloc[indexacion:,:]\n",
    "        transtable.columns = ['Distrito','Casos']\n",
    "        \n",
    "        # Agregar etiquetas\n",
    "        transtable['Semana'] = pdfscraping['semana'][i]\n",
    "        transtable['Región'] = agrupar\n",
    "\n",
    "        hemeroteca += [transtable]\n",
    "    \n",
    "    if i in [5,10,15,20,25,30,35,40,45,50]:\n",
    "        print(f'Checkpoint {i}: {datetime.now()}')\n",
    "\n",
    "# Guardar variable como backup\n",
    "with open(\"anexos/pdfs2023/tablas.obj\",'wb') as filehandler: # Guardarlo para reusarlo en otra sesión\n",
    "    pickle.dump(hemeroteca,filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a6cc3bf-fa00-4f94-b4fb-ba685319f7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No se rehace todo el largo proceso: abre el archivo pickle\n",
    "with open(\"anexos/pdfs2023/tablas.obj\",'rb') as filehandler:\n",
    "    hemeroteca = pickle.load(filehandler)\n",
    "\n",
    "dfs = []\n",
    "for lista_df in dict(hemeroteca).values():\n",
    "    dfs.extend(lista_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dc5d496-f521-4c84-ac81-8d1495aad89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distrito</th>\n",
       "      <th>Casos</th>\n",
       "      <th>Semana</th>\n",
       "      <th>Región</th>\n",
       "      <th>Provincia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAN JUAN DE LURIGANCHO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>LIMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SANTIAGO DE SURCO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>LIMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>LIMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LURIGANCHO</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>LIMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COMAS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>LIMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503</th>\n",
       "      <td>CHILCA</td>\n",
       "      <td>6.0</td>\n",
       "      <td>52</td>\n",
       "      <td>Lima Region</td>\n",
       "      <td>CAÑETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2504</th>\n",
       "      <td>IMPERIAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52</td>\n",
       "      <td>Lima Region</td>\n",
       "      <td>CAÑETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2505</th>\n",
       "      <td>SAN VICENTE DE CAÑETE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52</td>\n",
       "      <td>Lima Region</td>\n",
       "      <td>CAÑETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506</th>\n",
       "      <td>ASIA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52</td>\n",
       "      <td>Lima Region</td>\n",
       "      <td>CAÑETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2507</th>\n",
       "      <td>DEMAS DISTRITOS</td>\n",
       "      <td>2.0</td>\n",
       "      <td>52</td>\n",
       "      <td>Lima Region</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2508 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Distrito  Casos  Semana       Región Provincia\n",
       "0     SAN JUAN DE LURIGANCHO    1.0       1        False      LIMA\n",
       "1          SANTIAGO DE SURCO    1.0       1        False      LIMA\n",
       "2                        ATE    2.0       1        False      LIMA\n",
       "3                 LURIGANCHO    2.0       1        False      LIMA\n",
       "4                      COMAS    0.0       1        False      LIMA\n",
       "...                      ...    ...     ...          ...       ...\n",
       "2503                  CHILCA    6.0      52  Lima Region    CAÑETE\n",
       "2504                IMPERIAL    0.0      52  Lima Region    CAÑETE\n",
       "2505   SAN VICENTE DE CAÑETE    0.0      52  Lima Region    CAÑETE\n",
       "2506                    ASIA    1.0      52  Lima Region    CAÑETE\n",
       "2507         DEMAS DISTRITOS    2.0      52  Lima Region       NaN\n",
       "\n",
       "[2508 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# limpieza de la tabla recopilada de los pdfs\n",
    "semanas = pd.concat(dfs, axis=0,ignore_index=True)\n",
    "semanas = semanas.loc[~(semanas['Distrito']=='') & (~semanas['Distrito'].str.contains('Total'))]\n",
    "semanas['Casos'] = pd.to_numeric(semanas['Casos'], errors='coerce')\n",
    "semanas = semanas[pd.notnull(semanas['Casos'])]\n",
    "\n",
    "distrital = gpd.read_file('anexos/distritos/distritos-peru@bogota-laburbano.geojson')\n",
    "distrital = distrital[(distrital['nombdep']=='LIMA')|(distrital['nombdep']=='CALLAO')][['nombdist','nombprov']]\n",
    "distrital = distrital.iloc[:-1,:]\n",
    "\n",
    "distrital.columns = ['Distrito','Provincia']\n",
    "semanas = semanas.merge(distrital,how='left',on=\"Distrito\")\n",
    "semanas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960c9211-60f5-4c6f-b456-1ec267208335",
   "metadata": {},
   "source": [
    "#### Observaciones con la tabla total\n",
    "\n",
    "Tablas vacías no correspondientes:\n",
    "* BARRANCA solo ha tenido 3 casos: 1 en PARAMONGA, 2 en SUPE.\n",
    "* CAJATAMBO solo ha tenido 2 casos registrados en GORGOR.\n",
    "* CANTA ha tenido solo dos casos en HUAMANTANGA\n",
    "* HUARAL solo ha tenido 4 casos: 3 en HUARAL, 1 en AUCALLAMA\n",
    "* HUAURA ha tenido 3 casos: 2 en Huacho y 1 en Sayan.\n",
    "\n",
    "Tablas vacías correctas:\n",
    "* OYON no tiene registros\n",
    "* YAUYOS no tiene registritos\n",
    "\n",
    "Tablas que arreglar:\n",
    "* HUAROCHIRI tiene un total de casos 4 valores menor que el consolidado de 2023.\n",
    "* CALLAO tiene muchos registros con cantidad de casos 0.\n",
    "* LIMA tiene muchos registros duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42194df4-2b17-4a23-a5b8-5847160497df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de la tabla:  (1025, 5)\n",
      "Cantidad de casos acumulados en 2023:  16464.0\n"
     ]
    }
   ],
   "source": [
    "provincias = list(distrital['Provincia'].value_counts().index)\n",
    "\n",
    "for prov in provincias:\n",
    "    ejecutar = f\"\"\"\n",
    "{prov} = semanas[semanas['Distrito'].isin(distrital[distrital['Provincia']=='{prov}']['Distrito'])]\n",
    "\"\"\"\n",
    "    exec(ejecutar)\n",
    "\n",
    "LIMA = LIMA[(LIMA['Provincia']=='LIMA')&(LIMA['Casos']!=0)]\n",
    "LIMA.drop_duplicates(subset=['Distrito','Semana'],inplace=True)\n",
    "\n",
    "HUAROCHIRI = HUAROCHIRI[(HUAROCHIRI['Provincia']=='HUAROCHIRI')&(HUAROCHIRI['Casos']!=0)]\n",
    "HUAROCHIRI.at[895,'Casos'] = 28 # (+4) En otras fuente, \n",
    "# sale que San Antonio en Huarochiri concentra una gran cantidad de casos. Por ello, para cubrir sus casos totales,\n",
    "# se añadirán a su semana con más casos\n",
    "\n",
    "CALLAO = semanas[semanas['Distrito'].isin(distrital[distrital['Provincia']=='CALLAO']['Distrito'])]\n",
    "\n",
    "agreg = {\n",
    "    'Provincia': ['BARRANCA', 'BARRANCA', 'CAJATAMBO', 'CANTA', 'HUARAL', 'HUARAL', 'HUAURA', 'HUAURA'],\n",
    "    'Distrito': ['PARAMONGA', 'SUPE', 'GORGOR', 'HUAMANTANGA', 'HUARAL', 'AUCALLAMA', 'HUACHO', 'SAYAN'],\n",
    "    'Semana': [20, 20, 10, 18, 17, 42, 21, 22],\n",
    "    'Casos': [1, 2, 2, 2, 3, 1, 2, 1]\n",
    "}\n",
    "\n",
    "tabla2023 = pd.concat([LIMA, CALLAO, HUAROCHIRI,pd.DataFrame(agreg)],axis=0,ignore_index=True)\n",
    "tabla2023['Año'] = 2023\n",
    "base2023 = tabla2023.sort_values(['Semana']).reset_index()[['Año','Provincia','Distrito','Semana','Casos']]\n",
    "base2023.to_csv('anexos/incidencias_dengue/2023.csv')\n",
    "\n",
    "print('Dimensiones de la tabla: ',base2023.shape)\n",
    "print('Cantidad de casos acumulados en 2023: ',base2023['Casos'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a6a2b0-389c-4fdd-81bf-b508b8d44988",
   "metadata": {},
   "source": [
    "### 1.1.4. Concatenación y preparación de las tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "477df98b-d545-48aa-af8d-d0c87d59ed72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar tablas\n",
    "base = pd.concat([base2022,base2023,base2024],axis=0,ignore_index=True)\n",
    "base['Semana'].replace(diccionario_meses,inplace=True)\n",
    "base.drop(base[base['Semana']==53].index,inplace=True)\n",
    "base.columns = ['Año','Provincia','Distrito','Mes','Casos']\n",
    "\n",
    "# Agrupar casos por meses\n",
    "base.set_index(['Año','Provincia','Distrito','Mes'],inplace=True)\n",
    "base = base.groupby(level=[0,1,2,3])['Casos'].sum()\n",
    "base = base.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b98c568-0b40-4901-b3ee-d9fe08c82e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020  -  2024-04-28 22:17:11.933329\n",
      "2021  -  2024-04-28 22:17:34.647983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agregar filas con casos igual a 0\n",
    "pairs = {(row['Provincia'], row['Distrito']) for _, row in distrital.iterrows()}\n",
    "\n",
    "años = [2020,2021,2022,2023,2024]\n",
    "meses = list(diccionario_meses.values())\n",
    "\n",
    "for año in años:\n",
    "    print(año, ' - ', datetime.now())\n",
    "    for mes in meses:\n",
    "        for provincia, distrito in pairs:\n",
    "            registro = {'Año':año,'Provincia':provincia,'Distrito':distrito,'Mes':mes,'Casos':0}\n",
    "            base.loc[base.shape[0]] = registro\n",
    "\n",
    "base.drop_duplicates(subset=['Año','Provincia','Distrito','Mes'],inplace=True,ignore_index=True)\n",
    "base.drop(base[(base['Año']==2024) & (base['Mes'].isin(['Mayo','Junio','Julio','Agosto','Setiembre','Octubre','Noviembre','Diciembre']))].index,inplace=True)\n",
    "base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a588ce-0e7b-43b5-baf1-f1b606b00f61",
   "metadata": {},
   "source": [
    "Ya se tienen ahora todos los distritos mapeados para la serie temporal. En la exploración, se observa que una 'ñ' de Breña no se registró bien, de modo que se corregirá."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cddf6a07-84fc-4456-a6c2-3627f5841538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Distrito\n",
       "SAN LUIS       104\n",
       "SAN ANTONIO    104\n",
       "LARAOS         104\n",
       "MIRAFLORES     104\n",
       "VIÑAC           52\n",
       "              ... \n",
       "SAN BARTOLO     52\n",
       "SANTA ROSA      52\n",
       "SURQUILLO       52\n",
       "BARRANCA        52\n",
       "NAVAN           52\n",
       "Name: count, Length: 174, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.iloc[3136,4] = 1\n",
    "base = base.drop(66)\n",
    "\n",
    "base['Distrito'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1fea4375-cf21-4806-bee5-ff77b6e374dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exportación\n",
    "base.to_csv('datasets/dengue.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be11bb6e-d159-4a5d-b058-4adcc4018945",
   "metadata": {},
   "source": [
    "### 1.1.* Importación directa de tabla completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4de1d96d-f583-4173-9a11-7abd4fc11c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Año</th>\n",
       "      <th>Provincia</th>\n",
       "      <th>Distrito</th>\n",
       "      <th>Mes</th>\n",
       "      <th>Casos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>CALLAO</td>\n",
       "      <td>VENTANILLA</td>\n",
       "      <td>Abril</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>CALLAO</td>\n",
       "      <td>VENTANILLA</td>\n",
       "      <td>Marzo</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>LIMA</td>\n",
       "      <td>ATE</td>\n",
       "      <td>Abril</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>LIMA</td>\n",
       "      <td>ATE</td>\n",
       "      <td>Marzo</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>LIMA</td>\n",
       "      <td>ATE</td>\n",
       "      <td>Mayo</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9251</th>\n",
       "      <td>2024</td>\n",
       "      <td>YAUYOS</td>\n",
       "      <td>COCHAS</td>\n",
       "      <td>Abril</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9252</th>\n",
       "      <td>2024</td>\n",
       "      <td>YAUYOS</td>\n",
       "      <td>ALLAUCA</td>\n",
       "      <td>Abril</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9253</th>\n",
       "      <td>2024</td>\n",
       "      <td>HUARAL</td>\n",
       "      <td>PACARAOS</td>\n",
       "      <td>Abril</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9254</th>\n",
       "      <td>2024</td>\n",
       "      <td>HUAROCHIRI</td>\n",
       "      <td>SAN LORENZO DE QUINTI</td>\n",
       "      <td>Abril</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9255</th>\n",
       "      <td>2024</td>\n",
       "      <td>OYON</td>\n",
       "      <td>NAVAN</td>\n",
       "      <td>Abril</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9256 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Año   Provincia               Distrito    Mes  Casos\n",
       "0     2020      CALLAO             VENTANILLA  Abril    1.0\n",
       "1     2020      CALLAO             VENTANILLA  Marzo    3.0\n",
       "2     2020        LIMA                    ATE  Abril    3.0\n",
       "3     2020        LIMA                    ATE  Marzo    1.0\n",
       "4     2020        LIMA                    ATE   Mayo   21.0\n",
       "...    ...         ...                    ...    ...    ...\n",
       "9251  2024      YAUYOS                 COCHAS  Abril    0.0\n",
       "9252  2024      YAUYOS                ALLAUCA  Abril    0.0\n",
       "9253  2024      HUARAL               PACARAOS  Abril    0.0\n",
       "9254  2024  HUAROCHIRI  SAN LORENZO DE QUINTI  Abril    0.0\n",
       "9255  2024        OYON                  NAVAN  Abril    0.0\n",
       "\n",
       "[9256 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = pd.read_csv('datasets/dengue.csv')\n",
    "base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d38beda-b368-4f62-996d-b825aa829b0e",
   "metadata": {},
   "source": [
    "## 1.2. Importación y preparación de archivos ShapeFile para la visualización provincial y distrital del Perú.\n",
    "\n",
    "* FUENTE: https://www.geogpsperu.com/2018/02/limite-provincial-politico-shapefile.html\n",
    "* AUTOR: GEO GPS PERÚ (recopilado del Instituto Nacional de Estadística)\n",
    "* ÚLTIMA ACTUALIZACIÓN: 2023\n",
    "* ARCHIVOS DESCARGADOS: 'Límites_distritales.rar' y 'Límites_provinciales.rar' (INEI, 2023)\n",
    "\n",
    "Los archivos descargados contienen la información poligonal de los distritos y las provincias de todo el Perú, que luego será utilizada para realizar el análisis espacial pertinente en el API de OpenStreetMaps. La variable de interés para la tarea es 'geometry'; las de unión, 'provincia' y 'distrito'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7ee74f70-e824-411e-a2f3-df972b572c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de distritos.shp: (1891, 10) \n",
      "Lista de atributos: ['UBIGEO', 'CCDD', 'CCPP', 'CCDI', 'DEPARTAMEN', 'PROVINCIA', 'DISTRITO', 'OBJECTID', 'ESRI_OID', 'geometry'] \n"
     ]
    }
   ],
   "source": [
    "# Importación de valores geométricos para visualización espacial\n",
    "\n",
    "distrital = gpd.read_file('anexos/distritos/distritos.shp')\n",
    "print(f'Dimensiones de distritos.shp: {distrital.shape} \\nLista de atributos: {list(distrital.columns)} ') # (1891 filas, 10 columnas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c224f27-597f-4e7e-94b8-031258adeb49",
   "metadata": {},
   "source": [
    "### Registros borrados\n",
    "\n",
    "En ambas tablas, nos quedaremos exclusivamente con los registros que corresponden a los departamentos de Lima y El Callao. Para ello, se realiza una selección de filas donde los valores de las columnas 'DEPARTAMEN' sean 'LIMA' o 'CALLAO'.\n",
    "\n",
    "### Columnas mantenidas\n",
    "* DISTRITO (solo tabla distrito): etiqueta de nombre de distrito.\n",
    "* PROVINCIA: etiqueta de nombre de provincia.\n",
    "* geometry: contiene la información geométrica de la zona.\n",
    "\n",
    "Asimismo, se pasarán los nombres de las columnas a minúsculas para mantener integridad de nombre de columnas con las tablas que se trabajarán más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "28558bcf-2913-4962-b640-426bc7b0fd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de distrital: (178, 4)\n"
     ]
    }
   ],
   "source": [
    "# Pasando los nombres de las columnas a minúsculas\n",
    "\n",
    "distrital.columns = distrital.columns.str.lower()\n",
    "#base.columns = base.columns.str.lower()\n",
    "\n",
    "# Selección de registros y proyección de atributos de interés\n",
    "\n",
    "distrital = distrital.loc[((distrital['departamen']=='LIMA') | (distrital['departamen']=='CALLAO'))].reset_index()\n",
    "distrital = distrital[['objectid','provincia','distrito','geometry']]\n",
    "\n",
    "print(f'Dimensiones de distrital: {distrital.shape}') # (178 filas, 4 columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1771e4fb-130a-4d25-bda2-f71dab8b79c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completitud de datos en distritos (filas totales: 178): \n",
      "objectid     178\n",
      "provincia    178\n",
      "distrito     178\n",
      "geometry     178\n",
      "dtype: int64 \n",
      "\n",
      "Completitud de datos en provincial (filas totales: 11): \n",
      "objectid     11\n",
      "provincia    11\n",
      "geometry     11\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Completitud de datos en distritos\n",
    "print(f'Completitud de datos en distritos (filas totales: 178): \\n{distrital.count()} \\n\\nCompletitud de datos en provincial (filas totales: 11): \\n{provincial.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfd28e0-465c-4188-b435-f41ef243904f",
   "metadata": {},
   "source": [
    "Ningún dato faltante en ambas tablas. Podemos ya trabajar con estas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3684d928-9e73-4630-b751-41fe3c903656",
   "metadata": {},
   "source": [
    "La totalidad de los datos de las dos tablas se agrupan satisfactoriamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60af263",
   "metadata": {},
   "source": [
    "# 2. Variables climatológicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2365e9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from io import StringIO\n",
    "\n",
    "def read_concat(prefijo: str):\n",
    "    dfs = []\n",
    "    \n",
    "    for filename in os.listdir('anexos/clima'):\n",
    "        if filename.startswith(prefijo) and filename.endswith('.csv'):\n",
    "            dfs.append(pd.read_csv(os.path.join('anexos/clima',filename)))\n",
    "            \n",
    "    concat_df = pd.concat(dfs,ignore_index=True)\n",
    "    return concat_df\n",
    "\n",
    "def segment(df):\n",
    "    return\n",
    "\n",
    "def fix_date(df):\n",
    "    month_map = {\n",
    "        'enero': '01',\n",
    "        'febrero': '02',\n",
    "        'marzo': '03',\n",
    "        'abril': '04',\n",
    "        'mayo': '05',\n",
    "        'junio': '06',\n",
    "        'julio': '07',\n",
    "        'agosto': '08',\n",
    "        'septiembre': '09',\n",
    "        'octubre': '10',\n",
    "        'noviembre': '11',\n",
    "        'diciembre': '12'\n",
    "    }\n",
    "    df['Fecha'] = df.apply(lambda row: f\"{row['Año']}-{month_map[row['Mes']]}-{str(row['Día']).zfill(2)}\", axis=1)\n",
    "    columns = ['Fecha'] + [col for col in df.columns if col not in ['Año', 'Mes', 'Día', 'Fecha']]\n",
    "    df = df[columns]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def extract_number(value):\n",
    "    if pd.isna(value):\n",
    "        return value\n",
    "    value = value.replace(',', '.').replace('−', '-')\n",
    "\n",
    "    return float(value.split()[0])\n",
    "\n",
    "def transform_numbers(df):\n",
    "    df['Min'] = df['Min'].apply(extract_number)\n",
    "    df['Max'] = df['Max'].apply(extract_number)\n",
    "    return df\n",
    "\n",
    "def clean_csv(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    cleaned_lines = []\n",
    "    buffer = \"\"\n",
    "    for index, line in enumerate(lines):\n",
    "        if index == 0:\n",
    "            cleaned_lines.append(line.strip())  # Agregar la primera línea como encabezado\n",
    "            continue\n",
    "        if re.match(r'^\\d{4}-\\d{2}-\\d{2}', line):\n",
    "            if buffer:\n",
    "                cleaned_lines.append(buffer)\n",
    "            buffer = line.strip()\n",
    "        else:\n",
    "            buffer += \" \" + line.strip()\n",
    "\n",
    "    # Añadir la última línea procesada\n",
    "    if buffer:\n",
    "        cleaned_lines.append(buffer)\n",
    "\n",
    "    # Crear un dataframe a partir de las líneas limpias\n",
    "    cleaned_data = \"\\n\".join(cleaned_lines)\n",
    "    df = pd.read_csv(StringIO(cleaned_data))\n",
    "    return df\n",
    "\n",
    "def imputar_datos(df):\n",
    "    # Convertir la columna de fecha a datetime\n",
    "    df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "    \n",
    "    # Extraer el año y mes\n",
    "    df['Año'] = df['Fecha'].dt.year\n",
    "    df['Mes'] = df['Fecha'].dt.month\n",
    "    \n",
    "    # Seleccionar solo las columnas numéricas\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    \n",
    "    # Agrupar por año, mes, provincia y distrito\n",
    "    grouped = df.groupby(['Año', 'Mes', 'Provincia', 'Distrito'])\n",
    "    \n",
    "    # Imputar valores nulos con la media de cada grupo solo en columnas numéricas\n",
    "    df_imputed = df.copy()\n",
    "    df_imputed[numeric_cols] = grouped[numeric_cols].transform(lambda x: x.fillna(x.mean()))\n",
    "    \n",
    "    # Eliminar las columnas 'Año' y 'Mes' añadidas para la agrupación\n",
    "    df_imputed.drop(columns=['Año', 'Mes'], inplace=True)\n",
    "    \n",
    "    return df_imputed\n",
    "\n",
    "def merge_dfs(dfs, on_columns):\n",
    "    merged_df = dfs[0]\n",
    "    for df in dfs[1:]:\n",
    "        merged_df = merged_df.merge(df, on=on_columns, how='outer')\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9c2239",
   "metadata": {},
   "source": [
    "## 2.1. Limpieza de cada datasets de variables climatológicas scrapeadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7864e8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ------------\n",
    "# Rain-3h\n",
    "\n",
    "rain_3h = clean_csv(r'anexos\\clima\\rain-3h.csv')\n",
    "rain_3h['Min_text'] = rain_3h.apply(lambda row: row['Min'].split(' ')[-1] if isinstance(row['Min'], str) and row['Min'].split(' ')[-1] != 'mm' else 'Despejado', axis=1)\n",
    "rain_3h['Max_text'] = rain_3h.apply(lambda row: row['Max'].split(' ')[-1] if isinstance(row['Max'], str) and row['Max'].split(' ')[-1] != 'mm' else 'Despejado', axis=1)\n",
    "rain_3h['Weather'] = np.where(\n",
    "    (rain_3h['Min_text'] == 'Despejado') & (rain_3h['Max_text'] == 'Despejado'), 'Despejado',\n",
    "    np.where(rain_3h['Min_text'] != 'Despejado', rain_3h['Min_text'], rain_3h['Max_text'])\n",
    ")\n",
    "rain_3h = transform_numbers(rain_3h)\n",
    "rain_3h = imputar_datos(rain_3h)\n",
    "rain_3h = rain_3h.filter(['Fecha','Semana','Provincia','Distrito','Weather','Min','Max'])\n",
    "rain_3h.columns = ['Fecha','Semana','Provincia','Distrito','Clima','Pluvio_Min','Pluvio_Max']\n",
    "\n",
    "# ------------\n",
    "# Temperature-2m\n",
    "\n",
    "temp = read_concat('temperature-2m')\n",
    "temp = imputar_datos(transform_numbers(temp))\n",
    "temp.columns = ['Fecha','Semana','Provincia','Distrito','Temp_Min','Temp_Max']\n",
    "\n",
    "# ------------\n",
    "# Clouds-total\n",
    "\n",
    "clouds = read_concat('clouds-total')\n",
    "clouds = imputar_datos(transform_numbers(clouds))\n",
    "clouds['Min'] = clouds['Min']/100\n",
    "clouds = clouds.filter(['Fecha','Semana','Provincia','Distrito','Min'])\n",
    "clouds.columns = ['Fecha','Semana','Provincia','Distrito','Nubosidad']\n",
    "\n",
    "# ------------\n",
    "# Wind-10m\n",
    "\n",
    "wind = fix_date(read_concat('wind-10m'))\n",
    "wind = imputar_datos(transform_numbers(wind))\n",
    "wind.columns = ['Fecha','Provincia','Distrito','Semana','Viento_Min','Viento_Max']\n",
    "\n",
    "# ------------\n",
    "# Pressure\n",
    "\n",
    "pressure = fix_date(read_concat('pressure'))\n",
    "pressure = imputar_datos(transform_numbers(pressure))\n",
    "pressure.drop(columns=['Max'],inplace=True)\n",
    "pressure.columns = ['Fecha','Provincia','Distrito','Semana','Presión']\n",
    "\n",
    "# ------------\n",
    "# Dew\n",
    "\n",
    "dew = pd.read_csv('anexos/clima/dew.csv')\n",
    "dew = imputar_datos(transform_numbers(dew))\n",
    "dew.drop(columns=['Max'],inplace=True)\n",
    "dew.columns = ['Fecha','Semana','Provincia','Distrito','Punto_Rocío']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa26d6b",
   "metadata": {},
   "source": [
    "## 2.2. Concatenación de los datos en un solo dataset metereológico\n",
    "\n",
    "Comprendiendo solo Lima Metropolitana y El Callao."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee488f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Semana</th>\n",
       "      <th>Pluvio_Min</th>\n",
       "      <th>Pluvio_Max</th>\n",
       "      <th>Nubosidad</th>\n",
       "      <th>Presión</th>\n",
       "      <th>Viento_Min</th>\n",
       "      <th>Viento_Max</th>\n",
       "      <th>Temp_Min</th>\n",
       "      <th>Temp_Max</th>\n",
       "      <th>Punto_Rocío</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16450</td>\n",
       "      <td>16450.000000</td>\n",
       "      <td>13000.000000</td>\n",
       "      <td>13000.000000</td>\n",
       "      <td>10920.000000</td>\n",
       "      <td>12990.000000</td>\n",
       "      <td>13000.000000</td>\n",
       "      <td>13000.000000</td>\n",
       "      <td>12450.000000</td>\n",
       "      <td>13000.000000</td>\n",
       "      <td>13000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2022-02-28 03:30:05.471124736</td>\n",
       "      <td>25.112462</td>\n",
       "      <td>0.014367</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.564348</td>\n",
       "      <td>1010.888395</td>\n",
       "      <td>5.858724</td>\n",
       "      <td>12.495038</td>\n",
       "      <td>17.719351</td>\n",
       "      <td>21.750154</td>\n",
       "      <td>15.971929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-128.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2021-02-07 00:00:00</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1012.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022-02-22 00:00:00</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1014.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023-03-16 00:00:00</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1015.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024-04-30 00:00:00</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1020.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>15.503666</td>\n",
       "      <td>0.110468</td>\n",
       "      <td>0.009956</td>\n",
       "      <td>0.288507</td>\n",
       "      <td>48.683563</td>\n",
       "      <td>3.833698</td>\n",
       "      <td>2.724352</td>\n",
       "      <td>3.087386</td>\n",
       "      <td>3.392340</td>\n",
       "      <td>2.968127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Fecha        Semana    Pluvio_Min  \\\n",
       "count                          16450  16450.000000  13000.000000   \n",
       "mean   2022-02-28 03:30:05.471124736     25.112462      0.014367   \n",
       "min              2020-01-01 00:00:00      1.000000      0.000000   \n",
       "25%              2021-02-07 00:00:00     11.000000      0.000000   \n",
       "50%              2022-02-22 00:00:00     24.000000      0.000000   \n",
       "75%              2023-03-16 00:00:00     39.000000      0.000000   \n",
       "max              2024-04-30 00:00:00     53.000000      4.300000   \n",
       "std                              NaN     15.503666      0.110468   \n",
       "\n",
       "         Pluvio_Max     Nubosidad       Presión    Viento_Min    Viento_Max  \\\n",
       "count  13000.000000  10920.000000  12990.000000  13000.000000  13000.000000   \n",
       "mean       0.000394      0.564348   1010.888395      5.858724     12.495038   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.300000   1012.000000      3.000000     11.000000   \n",
       "50%        0.000000      0.600000   1014.000000      5.000000     12.000000   \n",
       "75%        0.000000      0.800000   1015.000000      8.000000     14.000000   \n",
       "max        0.800000      1.000000   1020.000000    254.000000     25.000000   \n",
       "std        0.009956      0.288507     48.683563      3.833698      2.724352   \n",
       "\n",
       "           Temp_Min      Temp_Max   Punto_Rocío  \n",
       "count  12450.000000  13000.000000  13000.000000  \n",
       "mean      17.719351     21.750154     15.971929  \n",
       "min     -128.000000     14.000000     -1.000000  \n",
       "25%       15.000000     19.000000     14.000000  \n",
       "50%       18.000000     22.000000     16.000000  \n",
       "75%       20.000000     24.000000     18.000000  \n",
       "max       24.000000     31.000000     24.000000  \n",
       "std        3.087386      3.392340      2.968127  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = [rain_3h,clouds,pressure,wind,temp,dew]\n",
    "columns = ['Fecha','Semana','Provincia','Distrito']\n",
    "\n",
    "clima = merge_dfs(dfs,columns)\n",
    "clima = clima.loc[clima['Provincia'].isin(['LIMA','CALLAO']),:]\n",
    "clima.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6697ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "clima.to_csv(r'datasets\\variables-climatológicas\\metereologia.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
